# <p align="center">SimMark: A Robust Sentence-Level Similarity-Based Watermarking Algorithm for Large Language Models</p>

<p align="center">
  <br>
  <a href="??"><img alt="Paper" src="https://img.shields.io/badge/ðŸ“ƒ-Paper-808080"></a>
  <a href="https://simmark.github.io/"><img alt="Website" src="https://img.shields.io/badge/%F0%9F%8C%90-Website-008080"></a>
</p>

## Abstract
The rapid proliferation of large language models (LLMs) has created an urgent need for reliable methods to detect whether a text is generated by such models. 
In this paper, we propose _**SimMark**_, a posthoc watermarking algorithm that makes LLMs' outputs traceable without requiring access to the model's internal logits, enabling compatibility with a wide range of LLMs, including API-only models.
By leveraging the similarity of semantic sentence embeddings and rejection sampling to impose detectable statistical patterns imperceptible to humans, and employing a _soft_ counting mechanism, _SimMark_ achieves robustness against paraphrasing attacks.
Experimental results demonstrate that _SimMark_ sets a new benchmark for robust watermarking of LLM-generated content, surpassing prior sentence-level watermarking techniques in robustness, sampling efficiency, and applicability across diverse domains, all while preserving the text quality.
<div align="center">
  <img src="https://github.com/user-attachments/assets/1550a812-fd1b-49a4-bb38-8a63b207773b" alt="image">
</div>

The input text is divided into individual sentences $`X_1`$ to $`X_N`$, which are embedded using a semantic embedding model, with optional PCA for dimensionality reduction. 
The similarity between consecutive sentence embeddings is computed. Sentences with similarities within a predefined interval $`[a, b]`$ are considered $`\color{ForestGreen}\textbf{valid}`$, while those outside are $`\textcolor{BrickRed}{\textbf{invalid}}`$. 
A _**soft**_-$`z`$-test is performed using the _soft_ count of $`\textcolor{BrickRed}{\mathrm{invalid/partially-valid}}`$ sentences to determine whether the text is watermarked.

## Overview of SimMark: A Similarity-Based Watermark
![image](https://github.com/user-attachments/assets/350a1c4b-de05-486c-8c50-4b5577130c10)

**Top:** ***Generation***. For each newly generated sentence ($X_{i+1}$), its embedding ($e_{i+1}$) is computed using the Instructor-Large model, optionally applying PCA for dimensionality reduction.  
The cosine similarity (or Euclidean distance) between $e_{i+1}$ and the embedding of the previous sentence ($e_i$), denoted as $s_{i+1}$, is calculated. If $s_{i+1}$ lies within the predefined interval $`[a, b]`$, the sentence is marked $`\color{ForestGreen}\textbf{valid}`$ and accepted.  
Otherwise, rejection sampling generates a new candidate sentence until validity is achieved or the iteration limit is reached. Once a sentence is accepted, the process repeats for subsequent sentences.  

**Bottom:** ***Detection (+ Paraphrase attack)***.  
Paraphrased versions of watermarked sentences are generated ($Y_{i}$), and their embeddings ($`e'_{i}`$) are computed. The similarity (or distance) between consecutive sentences in the paraphrased text is evaluated. If paraphrasing causes the similarity ($`s'_{i+1}`$) to fall outside $`[a, b]`$, it is mismarked as $`\textcolor{BrickRed}{\textbf{invalid}}`$.  
A *soft counting* mechanism (via function $c(s_{i+1})$ instead of a regular counting with a step function in the interval $`[a, b]`$) quantifies partial validity based on proximity to the interval bounds, enabling detection of watermarked text via the ***soft***-$`z`$-test even under paraphrase attacks.  
It should be emphasized that soft counting is always applied during detection, regardless of whether paraphrasing is present or not, as we cannot assume prior knowledge of paraphrasing.

## Citation
If you found this repository helpful, please don't forget to cite our paper:

```BibTeX

```
